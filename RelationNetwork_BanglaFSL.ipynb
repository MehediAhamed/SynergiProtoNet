{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWhTxhYS7TLf",
    "outputId": "c8d18b9a-7c68-440a-9eca-028ba33583ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NnxSUVIK73xa"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    colab = True\n",
    "except:\n",
    "    colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5vrGDXf7_Ly"
   },
   "outputs": [],
   "source": [
    "if colab is True:\n",
    "    # Running in Google Colab\n",
    "    # Clone the repo\n",
    "    !git clone https://github.com/sicara/easy-few-shot-learning\n",
    "    %cd easy-few-shot-learning\n",
    "    !pip install .\n",
    "else:\n",
    "    # Run locally\n",
    "    # Ensure working directory is the project's root\n",
    "    # Make sure easyfsl is installed!\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPdOROuFd18h"
   },
   "source": [
    "## Download or Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhLCcjsFtnYQ",
    "outputId": "0242b371-6d73-40df-dbc9-5cad8ef19dc8"
   },
   "outputs": [],
   "source": [
    "# Install gdown if not already installed\n",
    "!pip install gdown\n",
    "\n",
    "import gdown\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Google Drive file ID\n",
    "file_id = \"1bcgqIx48jbdNDS1JHySrzw1mzP1qW452\"\n",
    "destination = \"/content/BanglaLekha_Isolated_FSL.zip\"\n",
    "\n",
    "# Construct the download URL\n",
    "download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "# Download the file\n",
    "gdown.download(download_url, destination, quiet=False)\n",
    "\n",
    "# Unzip the file\n",
    "unzip_dir = \"/content/data\"\n",
    "os.makedirs(unzip_dir, exist_ok=True)\n",
    "with zipfile.ZipFile(destination, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52Pw8AbY3aHM",
    "outputId": "88e500cd-5bda-488e-8a36-964467c46b5a"
   },
   "outputs": [],
   "source": [
    "# Install gdown if not already installed\n",
    "!pip install gdown\n",
    "\n",
    "import gdown\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Google Drive file ID\n",
    "file_id = \"17DPq24559au2vEpH1QeAIL4FWs2jzr09\"\n",
    "destination = \"/content/BasicFinalDatabase_FSL.zip\"\n",
    "\n",
    "# Construct the download URL\n",
    "download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "# Download the file\n",
    "gdown.download(download_url, destination, quiet=False)\n",
    "\n",
    "# Unzip the file\n",
    "unzip_dir = \"/content/data\"\n",
    "os.makedirs(unzip_dir, exist_ok=True)\n",
    "with zipfile.ZipFile(destination, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhiI49Vl8DkZ"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from statistics import mean\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JE-g7hat8EWR"
   },
   "outputs": [],
   "source": [
    "random_seed = 30\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0z4qdEF-9Nhq"
   },
   "source": [
    "# Episodic Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZoaV-tbj8HJw"
   },
   "outputs": [],
   "source": [
    "n_way = 50\n",
    "n_shot = 5\n",
    "n_query = 10\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "n_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ii6KTrFt1u5O"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class BengaliCharactersDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        self.samples = []\n",
    "\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for img_file in os.listdir(class_dir):\n",
    "                if img_file.endswith('.png'):\n",
    "                    self.samples.append((os.path.join(class_dir, img_file), class_name))\n",
    "\n",
    "        # Debug: Print the first few samples\n",
    "        print(\"First few samples:\")\n",
    "        print(self.samples[:5])  # Adjust the number to print more or fewer samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label_str = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Convert label from string to integer\n",
    "        label = self.class_to_idx[label_str]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def get_labels(self):\n",
    "        return [label for _, label in self.samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vNtpJIwuXWq"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class BengaliCharactersDataset2(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        self.samples = []\n",
    "\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for img_file in os.listdir(class_dir):\n",
    "                if img_file.endswith('.bmp'):\n",
    "                    self.samples.append((os.path.join(class_dir, img_file), class_name))\n",
    "\n",
    "        # Debug: Print the first few samples\n",
    "        print(\"First few samples:\")\n",
    "        print(self.samples[:5])  # Adjust the number to print more or fewer samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label_str = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Convert label from string to integer\n",
    "        label = self.class_to_idx[label_str]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def get_labels(self):\n",
    "        return [label for _, label in self.samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lTdyVps2RLk",
    "outputId": "06b2c8eb-f024-4599-c7f2-cc996017769b"
   },
   "outputs": [],
   "source": [
    "image_size = 84  # Adjusted for ResNet, which typically expects larger input sizes\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),  # Random rotation between -10 and 10 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "train_set = BengaliCharactersDataset(root_dir='/content/data/BanglaLekha_Isolated_FSL/Train', transform=train_transforms)\n",
    "test_set = BengaliCharactersDataset(root_dir='/content/data/BanglaLekha_Isolated_FSL/Test', transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmWydVXk8JYI",
    "outputId": "1a14370b-b58f-4551-fdf8-16da00ad583c"
   },
   "outputs": [],
   "source": [
    "from easyfsl.samplers import TaskSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "n_tasks_per_epoch = 500\n",
    "n_validation_tasks = 100\n",
    "\n",
    "val_set = test_set\n",
    "\n",
    "train_set.get_labels = lambda: [\n",
    "    instance[1] for instance in train_set\n",
    "]\n",
    "\n",
    "val_set.get_labels = lambda: [\n",
    "    instance[1] for instance in val_set\n",
    "]\n",
    "\n",
    "# Those are special batch samplers that sample few-shot classification tasks with a pre-defined shape\n",
    "train_sampler = TaskSampler(\n",
    "    train_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_tasks_per_epoch\n",
    ")\n",
    "val_sampler = TaskSampler(\n",
    "    val_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_validation_tasks\n",
    ")\n",
    "# Finally, the DataLoader. We customize the collate_fn so that batches are delivered\n",
    "# in the shape: (support_images, support_labels, query_images, query_labels, class_ids)\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_sampler=train_sampler,\n",
    "    num_workers=n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=train_sampler.episodic_collate_fn,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_sampler=val_sampler,\n",
    "    num_workers=n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=val_sampler.episodic_collate_fn,\n",
    ")\n",
    "\n",
    "print(len(train_set), len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQ3g-54A8N-s"
   },
   "outputs": [],
   "source": [
    "#Only used this encoder for RelationNetworks few shot algorithm\n",
    "\n",
    "class CNNEncoder(nn.Module):\n",
    "    \"\"\"docstring for ClassName\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(3,64,kernel_size=3,padding=0),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "                        nn.Conv2d(64,64,kernel_size=3,padding=0),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "                        nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "                        nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU())\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        #out = out.view(out.size(0),-1)\n",
    "        return out # 64\n",
    "\n",
    "from easyfsl.methods import RelationNetworks, FewShotClassifier\n",
    "\n",
    "convolutional_network = CNNEncoder()\n",
    "few_shot_classifier = RelationNetworks(convolutional_network,feature_dimension = 64).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOdKOzj98RkB"
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Optimizer\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 30\n",
    "scheduler_milestones = [120, 160]\n",
    "scheduler_gamma = 0.1\n",
    "learning_rate = 1e-2\n",
    "tb_logs_dir = Path(\".\")\n",
    "\n",
    "train_optimizer = SGD(\n",
    "    few_shot_classifier.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4\n",
    ")\n",
    "train_scheduler = MultiStepLR(\n",
    "    train_optimizer,\n",
    "    milestones=scheduler_milestones,\n",
    "    gamma=scheduler_gamma,\n",
    ")\n",
    "\n",
    "tb_writer = SummaryWriter(log_dir=str(tb_logs_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ojLSBvch8U-a"
   },
   "outputs": [],
   "source": [
    "def training_epoch(\n",
    "    model: FewShotClassifier, data_loader: DataLoader, optimizer: Optimizer\n",
    "):\n",
    "    all_loss = []\n",
    "    model.train()\n",
    "    with tqdm(\n",
    "        enumerate(data_loader), total=len(data_loader), desc=\"Training\"\n",
    "    ) as tqdm_train:\n",
    "        for episode_index, (\n",
    "            support_images,\n",
    "            support_labels,\n",
    "            query_images,\n",
    "            query_labels,\n",
    "            _,\n",
    "        ) in tqdm_train:\n",
    "            optimizer.zero_grad()\n",
    "            model.process_support_set(\n",
    "                support_images.to(DEVICE), support_labels.to(DEVICE)\n",
    "            )\n",
    "            classification_scores = model(query_images.to(DEVICE))\n",
    "\n",
    "            loss = LOSS_FUNCTION(classification_scores, query_labels.to(DEVICE))\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            all_loss.append(loss.item())\n",
    "\n",
    "            tqdm_train.set_postfix(loss=mean(all_loss))\n",
    "\n",
    "    return mean(all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IG6pA52a8ZAZ",
    "outputId": "894e28e1-20d1-4c16-bd1e-491528979a92"
   },
   "outputs": [],
   "source": [
    "from easyfsl.utils import evaluate\n",
    "\n",
    "PATH = '/content/1shot_5way_BanglaRelation_BLF.pth'\n",
    "\n",
    "best_state = few_shot_classifier.state_dict()\n",
    "best_validation_accuracy = 0.0\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    average_loss = training_epoch(few_shot_classifier, train_loader, train_optimizer)\n",
    "    validation_accuracy = evaluate(\n",
    "        few_shot_classifier, val_loader, device=DEVICE, tqdm_prefix=\"Validation\"\n",
    "    )\n",
    "\n",
    "    if validation_accuracy > best_validation_accuracy:\n",
    "        best_validation_accuracy = validation_accuracy\n",
    "        best_state = few_shot_classifier.state_dict()\n",
    "        print(\"Ding ding ding! We found a new best model!\")\n",
    "\n",
    "    tb_writer.add_scalar(\"Train/loss\", average_loss, epoch)\n",
    "    tb_writer.add_scalar(\"Val/acc\", validation_accuracy, epoch)\n",
    "\n",
    "    # Warn the scheduler that we did an epoch\n",
    "    # so it knows when to decrease the learning rate\n",
    "    train_scheduler.step()\n",
    "\n",
    "    if epoch % 1 == 0 : torch.save(best_state, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jD---wAY8d1J",
    "outputId": "d5880faf-d555-476c-c8b5-674253081989"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_classifier.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-YALOOBJstS"
   },
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEakeF2Y8h-p"
   },
   "outputs": [],
   "source": [
    "n_test_tasks = 100\n",
    "\n",
    "test_set.get_labels = lambda: [\n",
    "    instance[1] for instance in test_set\n",
    "]\n",
    "\n",
    "test_sampler = TaskSampler(\n",
    "    test_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_test_tasks\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_sampler=test_sampler,\n",
    "    num_workers=n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=test_sampler.episodic_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zGp8gjVZ8k7p",
    "outputId": "9e1d2807-cd37-4efd-c9b0-57774ffa1e66"
   },
   "outputs": [],
   "source": [
    "from easyfsl.utils import evaluate\n",
    "accuracy = evaluate(few_shot_classifier, test_loader, device=DEVICE)\n",
    "print(f\"Average accuracy : {(100 * accuracy):.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6EGdusfEs3A"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import torch\n",
    "\n",
    "\n",
    "def evaluate_with_metrics(model, loader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, (support_images, support_labels, query_images, query_labels, _) in enumerate(loader):\n",
    "            model.process_support_set(support_images.to(device), support_labels.to(device))\n",
    "            outputs = model(query_images.to(device))\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.extend(query_labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "    return precision, recall, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uE5xJeMYEuTq",
    "outputId": "f1fbdbc2-28bf-4cbb-c99a-76e733194adf"
   },
   "outputs": [],
   "source": [
    "precision, recall, f1_score = evaluate_with_metrics(few_shot_classifier, test_loader, DEVICE)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1_score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
